# ğŸ¤– Chatbot Documentaire RAG â€” Retrieval-Augmented Generation

Ce projet implÃ©mente un **chatbot documentaire intelligent**, capable de rÃ©pondre Ã  des questions en langage naturel en utilisant vos propres documents (PDF, textes, rapports mÃ©tierâ€¦).

Il repose sur une architecture **RAG (Retrieval-Augmented Generation)** combinant :

- embeddings HuggingFace,
- une base vectorielle ChromaDB,
- et un modÃ¨le de gÃ©nÃ©ration OpenAI (GPT-4.1-mini par dÃ©faut).

Ce type de pipeline est aujourdâ€™hui utilisÃ© en entreprise pour :  
- automatiser du support,  
- analyser des documents internes,  
- interroger des bases documentaires mÃ©tier,  
- crÃ©er des assistants LLM privÃ©s.

---

# ğŸ¯ Objectif

Permettre Ã  un utilisateur de poser des questions naturelles sur ses documents et dâ€™obtenir des rÃ©ponses :

- prÃ©cises  
- contextualisÃ©es  
- sourcÃ©es par des extraits rÃ©els  

---

# ğŸ§± Architecture du projet

Voici le pipeline complet :




# ğŸ› ï¸ Stack technique

### **Langages & Frameworks**
- Python 3.10+
- Streamlit (application web)

### **LLM & NLP**
- HuggingFace SentenceTransformers â†’ `all-MiniLM-L6-v2` pour les embeddings  
- OpenAI GPT-4.1-mini (ou tout autre modÃ¨le compatible) pour la gÃ©nÃ©ration

### **Vector Database**
- ChromaDB (persistant)

### **Autres bibliothÃ¨ques**
- `pandas`, `numpy`
- `openai`
- `chromadb`
- `sentence-transformers`



# ğŸ“‚ Structure du projet


01-llm-rag-chatbot/
 â”œâ”€â”€ data/
 â”‚   â”œâ”€â”€ raw/                  # Fichiers dâ€™entrÃ©e (PDF, TXTâ€¦)
 â”‚   â””â”€â”€ processed/
 â”‚        â””â”€â”€ chroma_db/       # Base vectorielle persistante
 â”œâ”€â”€ src/
 â”‚   â”œâ”€â”€ ingest.py             # Extraction texte + crÃ©ation des chunks
 â”‚   â”œâ”€â”€ build_index.py        # Embeddings + insertion dans Chroma
 â”‚   â”œâ”€â”€ app.py                # Version console du chatbot RAG
 â”‚   â””â”€â”€ app_streamlit.py      # Application Streamlit
 â”œâ”€â”€ requirements.txt
 â”œâ”€â”€ .gitignore
 â””â”€â”€ README.md                 # (ce fichier)


## ğŸš€ Lancer le projet
bash
# Cloner le repo
- git clone https://github.com/Gwaldyso/01-llm-rag-chatbot.git
- cd 01-llm-rag-chatbot

# CrÃ©er et activer un environnement virtuel (optionnel mais recommandÃ©)

- python -m venv .venv
- .\.venv\Scripts\activate    # Windows


# Installer les dÃ©pendances
pip install -r requirements.txt

# Lancer le script principal (exemple)
python src/app.py


## Pipeline dâ€™utilisation
#ğŸ”¹ Ã‰tape 1 â€” DÃ©poser vos documents

Placez vos fichiers PDF/TXT dans :

data/raw/

---

#ğŸ”¹ Ã‰tape 2 â€” Ingestion & chunking
- ExÃ©cutez le script dâ€™ingestion pour extraire le texte et crÃ©er les chunks :
- Le script gÃ©nÃ¨re automatiquement :

---

#ğŸ”¹ Ã‰tape 3 â€” Construction de lâ€™index vectoriel
- Construisez lâ€™index (embeddings + stockage ChromaDB) :
- Lâ€™index vectoriel persistant sera crÃ©Ã© dans :

---

#ğŸ”¹ Ã‰tape 4 â€” Version console (CLI)
- Configurez votre clÃ© OpenAI : 
- Lancez le chatbot en mode console :

---

#ğŸ”¹ Ã‰tape 5 â€” Version web (Streamlit)
- Exportez votre clÃ© OpenAI :
- Lancez lâ€™interface web :


- AccÃ©dez ensuite Ã  :  
ğŸ‘‰ http://localhost:8501

- Vous verrez :
  - une zone pour poser vos questions  
  - une rÃ©ponse gÃ©nÃ©rÃ©e par le LLM  
  - un mode debug pour voir les chunks utilisÃ©s  


## âš™ï¸ FonctionnalitÃ©s

### ğŸ”¹ Chatbot documentaire intelligent
- Posez des questions en langage naturel sur vos documents.
- Obtenez des rÃ©ponses contextualisÃ©es et structurÃ©es.

### ğŸ”¹ Pipeline RAG complet
- Ingestion et dÃ©coupage des documents en chunks.
- Vectorisation (embeddings) et indexation dans une base vectorielle.
- Recherche sÃ©mantique des passages les plus pertinents.
- GÃ©nÃ©ration de la rÃ©ponse en sâ€™appuyant sur le contexte.

### ğŸ”¹ Deux modes dâ€™utilisation
- Mode console (CLI) : interaction dans le terminal.
- Interface web Streamlit : chatbot accessible via navigateur.

### ğŸ”¹ Architecture modulaire
- Scripts sÃ©parÃ©s pour :
  - lâ€™ingestion (`ingest.py`)
  - la construction de lâ€™index (`build_index.py`)
  - le chatbot console (`app.py`)
  - le chatbot web (`app_streamlit.py`)


## ğŸ§  Fonctionnement dÃ©taillÃ©

### ğŸ“Œ Embeddings â€” HuggingFace MiniLM-L6-v2
- ModÃ¨le : `sentence-transformers/all-MiniLM-L6-v2`
- CaractÃ©ristiques :
  - rapide
  - lÃ©ger
  - excellent rapport qualitÃ© / vitesse
- Utilisation :
  - transforme les questions et les chunks de texte en vecteurs numÃ©riques.
  - permet de mesurer la similaritÃ© entre la question et les passages de documents.

---

### ğŸ“Œ Vectorisation & Recherche â€” ChromaDB
- Base vectorielle : **ChromaDB** (mode persistant).
- RÃ´le :
  - stocker les embeddings des chunks.
  - faire de la recherche de similaritÃ© (kNN) pour retrouver les passages les plus proches de la question.
- Avantages :
  - simple Ã  utiliser en Python.
  - adaptÃ©e aux projets RAG de petite et moyenne taille.

---

### ğŸ“Œ GÃ©nÃ©ration â€” OpenAI GPT-4.1-mini
- ModÃ¨le utilisÃ© : `gpt-4.1-mini` (configurable).
- RÃ´le :
  - recevoir un **prompt** contenant :
    - le contexte (chunks retrouvÃ©s)
    - la question utilisateur
    - des consignes de rÃ©ponse (en franÃ§ais, strictement basÃ©e sur le contexte).
  - gÃ©nÃ©rer une rÃ©ponse claire, synthÃ©tique et structurÃ©e.
- Avantages :
  - bonne qualitÃ© de langage.
  - adaptÃ© Ã  des tÃ¢ches de rÃ©sumÃ©, rÃ©ponse Ã  des questions, reformulation.

---

## ğŸ§© Points forts du projet

### ğŸ”¹ Architecture RAG complÃ¨te
- Couverture de toutes les Ã©tapes :
  - ingestion
  - embeddings
  - indexation
  - retrieval
  - gÃ©nÃ©ration

### ğŸ”¹ Combinaison de technologies modernes
- Embeddings HuggingFace + ChromaDB + OpenAI :
  - montre une bonne comprÃ©hension des outils actuels de lâ€™IA gÃ©nÃ©rative.
  - facilement transposable dans un contexte entreprise.

### ğŸ”¹ Code structurÃ© et pÃ©dagogique
- SÃ©paration claire des responsabilitÃ©s :
  - `ingest.py` pour la prÃ©paration des donnÃ©es.
  - `build_index.py` pour la construction de lâ€™index.
  - `app.py` pour la version console.
  - `app_streamlit.py` pour la version web.
- Facile Ã  lire, Ã  maintenir et Ã  Ã©tendre.








